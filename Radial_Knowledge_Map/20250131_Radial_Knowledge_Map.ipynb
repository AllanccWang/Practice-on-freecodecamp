{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4d4fad7-4749-4398-a95f-da9208bb00cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import time\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44da28f8-8279-4ddb-a6eb-e3876955ce6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = \"Stock\"\n",
    "url = f\"https://en.wikipedia.org/wiki/\"\n",
    "resp = requests.get(url+keyword)\n",
    "soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13a80ad2-2009-482d-8e0e-c72cf9061958",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_content = soup.find(id='mw-content-text').find_all(\"p\",limit=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43b505ae-9c68-4cdf-91a4-78174dc12329",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import module\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import *\n",
    " \n",
    "#Check if a webpage exists\n",
    "def check_Topic_Connection(a_link):\n",
    "    sub_topic = a_link.split('/')[2]\n",
    "    #try block to read URL\n",
    "    try:\n",
    "        resp = requests.get(url+sub_topic)\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        sub_content = soup.find(id='mw-content-text').find_all(\"p\",limit=10)\n",
    "        sub_text = \"\"\n",
    "        for parag in sub_content:\n",
    "            sub_text += parag.get_text()\n",
    "        if (\"Stock\" in sub_text or \"stock\" in sub_text) and \"strategy\" in sub_text:\n",
    "            print(sub_topic)\n",
    "    except HTTPError as e:\n",
    "        print(\"HTTP error\", e)\n",
    "    except URLError as e:\n",
    "        print(\"Opps ! Page not found!\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6648b979-024d-487c-a95b-b376a6d6fd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Private_equity\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "corr_words = defaultdict(list)\n",
    "\n",
    "for ext_link in id_content:\n",
    "    a_tag = ext_link.find_all(name='a', href=re.compile(\"^(/wiki/)\")) #尋找開頭是「/wiki/」的字串\n",
    "    if len(a_tag) > 0: #如果有找到\n",
    "        for link_string in a_tag:\n",
    "            a_keyword = link_string.get_text()\n",
    "            a_link = link_string[\"href\"]\n",
    "            #print(f\"外部連結: [{a_keyword}]  {a_link}\")\n",
    "            check_Topic_Connection(a_link)\n",
    "            corr_words[keyword].append(a_keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a845bb38-8576-4eb0-a62b-92aaba34e01d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
